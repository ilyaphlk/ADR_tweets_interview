Решение задачи drug-drug-interaction extraction (DDI Extraction) позволило бы автоматически выделять информацию о взаимодействии лекарственных препаратов из текста, тем самым сократив время, необходимое на обновление базы данных взаимодействующих веществ.
Авторы статьи предлагают усовершенствованный подход к решению задачи DDI extraction. Утверждается, что для выделения информации из текста может быть полезно использовать не только текстовые эмбеддинги, получаемые напрямую из входной последовательности, но и графовое представление молекулярных структур действующих веществ.

В работе исследователи рассматривают комбинированную архитектуру нейросети. Первая часть - свёрточная нейронная сеть, состоящая из свёрточного слоя и отборочного слоя; исходная последовательность преобразуется в текстовые эмбеддинги заранее обученным энкодером word2vec, и подаётся на вход сети. Также создаются и подаются на вход позиционные эмбеддинги, соответствующие первому и второму веществу из целевой пары.
Вторая часть - свёрточная сеть на графах (GCN). Авторы статьи проводят анализ двух вариантов архитектуры GCN.
Первый вариант - NFP - подразумевает под собой последовательный (по времени) подсчёт скрытых состояний системы для каждой из вершин. Для этого суммируются скрытые состояния системы по всем соседям данной вершины (включая её саму) на предыдущем временном шаге. Полученная сумма взвешенно передаётся в сигмоидную функцию активации - результат этой операции и будет новым скрытым состоянием системы для данной вершины. Отметим, что скрытые состояния инициализируются "атомарными" признаками: типом атома соответствующего вершине, типами молекулярных связей с соседними вершинами. Наконец, финальная репрезентация графа молекулярных связей подсчитывается как взвешенная сумма всех скрытых состояний всех вершин графа в каждый из моментов времени, и эта сумма нормируется с помощью функции softmax.
Второй вариант GCN использует рекуррентную нейронную сеть GRU для подсчёта очередного скрытого состояния. Идея, в целом, та же: сначала подсчитывается взвешенная сумма скрытых состояний соседей вершины на предыдущем шаге; затем скрытое состояние вершины подсчитывается как результат работы GRU на конкатенации подсчитанной суммы и скрытого состояния вершины на предыдущем шаге. Однако итоговая репрезентация графа вычисляется иначе. Для каждой вершины в два различных полносвязных слоя подаются скрытое состояние вершины на последнем шаге и конкатенация первого и последнего состояния вершины соответственно. Далее берётся скалярное произведение полученных результатов и активириуется с помощью сигмоиды; сумма по активациям для всех вершин и будет выходом нейросети.
Способ предсказания наличия взаимодействия между парой молекул не зависит от архитектуры: для каждой молекулы строится её репрезентация, две репрезентации конкатенируются, и взвешенно подаются на вход сначала relu-слою, а затем softmax-слою.
Авторы объединяют свёрточную и графовую сеть путём конкатенации отборочного слоя свёрточной сети и полученной с помощью GCN репрезентации. Объединённые слои затем подаются на вход в финальный, полносвязный слой. В качестве минимизируемого функционала исследователи используют кросс-энтропию.

Подготовленный датасет для обучения модели также состоит из двух частей. Датасет для тренировки GCN был создан исследователями на основе базы данных DrugBank, в которой содержатся известные взаимодействующие пары веществ. Поскольку записи из DrugBank содержат лишь информацию о положительном классе, необходимо было дополнить датасет примерами отрицательного (невзаимодействующего класса). Авторы статьи предлагают составить отрицательный класс из случайных пар молекул, проследив при этом, чтобы в отрицательном классе не было сэмплов из положительного класса. Тренировочный датасет для свёрточной сети предоставлен DDIExtraction 2013 shared task, его исследователи разбивают на токены (целые слова), а также заменяют названия веществ на специальные токены, с учетом порядкового номера вещества в тексте.
Процесс обучения предложенной модели - поэтапный. Сначала на своём датасете обучается GCN, её веса фиксируются; Уже обученная GCN объединяется со свёрточной сетью (посредством полносвязного слоя), и на датасете свёрточной сети тренируется сверточная часть комбинированной сети - таким образом получается учитывать предсказания GCN в процессе обучения всей сети.

Авторы статьи заявляют о приросте F-меры на 2.39% на задании DDI Extraction по сравнению с методами, не использующими графовую репрезентацию взаимодействующих молекул в качестве признаков. При этом исследователи отмечают, что для корректности сравнение проводится с неансамблированными версиями сетей-предшественников. Также указывается, что добавление GCN к текстовой модели даёт особенно ощутимый прирост F-меры при выделении из текста взаимодействий вида Mechanism и Effect (до 4.31% и 3.17% соответственно).
Помимо этого, авторам исследования удалось достичь высокой accuracy (до 98%) в задании DDI Classification (binary) на датасете из пар молекул DrugBank с использованием лишь GCN-части модели. Однако необходимо помнить, что хотя и классы в этом датасете примерно равны по размеру, отрицательная часть датасета была сгенерирована случайным образом. Наконец, использование GCN-части для бинарной классификации взаимодействий на датасете DDI Extraction (все взаимодействия были помечены как положительный класс) не увенчалось успехом. Исходя из этого, исследователи делают вывод, что нельзя классифицировать взаимодействие в тексте, опираясь лишь на молекулярные репрезентации веществ.