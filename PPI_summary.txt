Подробное изучение межпротеиновых взаимодействий (protein-protein interaction, PPI) позволило бы получить больше информации о различных биологических процессах, происходящих внутри живых организмов, а также могло бы помочь в разработке новых лекарственных средств. До сих пор в исследованиях PPI методами NLP использовалась лишь текстовая информация для создания необходимых признаков. В то же время, во многих других задачах глубинного обучения хорошо себя проявил мультимодальный подход: признаки исследуемой сущности строятся на основе разных её характеристик. В своей статье авторы утверждают, что подобный подход мог бы найти применение и в задачах семейства PPI; в частности, для создания признаков они предлагают использовать не только текстовую информацию о протеинах, но и их трёхмерную структуру, а также нуклеотидные последовательности.

Авторы статьи отмечают, что в отличие от других ветвей глубинного обучения, BioNLP не может похвастаться большим числом мультимодальных датасетов, в особенности для решения задач, связанных с PPI. В своей работе исследователи выделяют две основных части: создание нового мультимодального датасета из открытых источников, а также создание мультимодальной архитектуры, задействующей механизм Внимания.

В качестве основы для нового датасета авторы выбрали два самых популярных текстовых датасета: BioInfer и HRPD50. Чтобы упростить исследование взаимодействий между протеинами, было решено в каждой новой записи рассматривать лишь одну пару веществ. Это привело к кратному увеличению размера датасета: если в исходной записи имелось k упоминаний белков, то модифицированных записей будет порядка k^2 / 2. Более того, если в исходной записи упоминания дублируются, это неизбежно приводит к большему числу невзаимодействующих пар в новом датасете, и, соответственно, дизбалансу положительного и отрицательного классов.
Для аугментации датасета структурными и нуклеотидными характеристиками белков, были использованы записи из корпусов NCBI и NCI. Пространственная структура в формате PDB или FASTA-последовательность каждого белка доступна для загрузки по соответсвующим идентификаторам (PDB ID, ensemble ID). Однако упомянутые корпуса содержат лишь связь PDB ID, ensemble ID и гена, отвечающего за производство данного белка в организме. Поэтому была использована ручная аннотация, сопоставляющая белки тем генам, в которых содержится информация о них. Авторы также отмечают, что разметку данных осуществяляли высококвалифицированные специалисты, доля разногласий составила меньше процента.

Текстовые признаки авторы предлагают получать следующим образом: модель BioBERT, предобученная на крупных корпусах медицинских текстов (PubMed, PMC), используется в качестве метаэнкодера: каждая запись подаётся на вход в BioBERT, чтобы полученное представление было использовано в качестве входной последовательности для первого BiLSTM-слоя. Авторы предлагают использовать 6 последовательных BiLSTM-слоёв: в качестве входа каждому слою (кроме первого) подаётся набор скрытых состояний предыдущего слоя на каждом из временных шагов; при этом прямые и обратные скрытые состояния конкатенируются между собой. Итоговый вектор-репрезентация получается аналогичным образом.
Чтобы получить признаки из FASTA-последовательностей, последовательности нуклеотидов сначала onehot-кодируются, затем служат входом для трёх последовательных свёрточных слоёв. После этого, вместо традиционного MaxPooling- или Averaging-слоя, выходы кодируются с помощью первичного и вторичного капсульных слоёв (главным преимуществом капсульной нейронной сети является то, что она сохраняет большое количество структурной информации, и, как следствие, проще интерпретируется). Полученный вектор - и есть искомая репрезентация.
Для получения структурных признаков координаты атомов из PDB-файла конвертируются в матрицу смежности, а также для каждого атома подсчитывается его вектор признаков, которые складываются в матрицу. Полученная информация задаёт графовое представление протеина, которое подаётся на вход свёрточной сети на графах (GCN, архитектуру авторы заимствуют из другого исследования). Результаты для каждого белка из пары конкатенируются, и результат конкатенации используется в дальнейшем как финальная репрезентация структурных свойств пары белков.
Каждая из репрезентаций подаётся на вход трансформер-модели (три энкодер-слоя). Исследователи используют трансформер для получения весов (встроенного) механизма Внимания; итоговый вектор признаков создаётся путём взвешенной конкатенации: каждая из выученных репрезентаций домножается на свои веса Внимания, а затем все они конкатенируются в один вектор. Этот вектор проходит через двуслойную полносвязную сеть, и затем служит входом для softmax-слоя, используемого для итоговой классификации.

Авторы исследования проводят подробный сравнительный анализ возможных комбинаций модальностей между собой. Каждая из частей предложенной архитектуры проверяется на предложенном датасете отдельно; затем тестируются парные комбинации частей; наконец, тестируется три варианта мультимодальных архитектур - модель, предложенная в статье, а также её модификации: модель без механизма внимания в конце, и модель, в которой информация о структуре белка обрабатывается свёрточной нейросетью, FASTA-последовательность - двусторонней LSTM-сетью.
Результаты сравнительного анализа таковы: мультимодальные архитектуры справляются с классификацией лучше бимодальных; аналогично бимодальные архитектуры проявляют себя лучше, чем унимодальные. Среди унимодальных архитектур наибольшие показатели точности/полноты/F-меры показывает пространственно-структурный подход - исходя из этого исследователи делают вывод, что наибольшую роль в классификации PPI играет именно структурная модальность. Также авторы заявляют о важности техники конкатенации результатов частей модели; это расуждение обосновано тем, что модель без механизма Внимания ведёт себя несколько хуже аналогичной модели с Вниманием.
На обоих датасетах авторы добиваются state-of-the-art результатов, в обоих случаях улучшая предыдущий результат по F-мере примерно на 7% в абсолютном выражении. Наконец, авторы проводят анализ ложных предсказаний модели и приходят к выводу, что чаще всего ошибки происходят на записях, содержащих большое число целевых сущностей. Также доля ошибок велика на тех записях, которые содержат большое число дублированных сущностей. Таким образом, представленная модель имеет потенциал к улучшению.

